{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa98979-d23c-4dec-ad38-9d713385687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements:\n",
    "# functions-framework\n",
    "# pandas\n",
    "# requests\n",
    "# bs4\n",
    "# sqlalchemy\n",
    "# pymysql\n",
    "\n",
    "import functions_framework\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import sqlalchemy\n",
    "import pymysql\n",
    "\n",
    "@functions_framework.http\n",
    "def insert_population_parameters(request):\n",
    "  connection_string = connection()\n",
    "  insert_population_data_in_SQL(connection_string)\n",
    "  return \"All Ok\"\n",
    "\n",
    "def connection():\n",
    "    schema = \"gans_data_pipeline\"  # update \"gans_data_pipeline\" to your actual MySql database (schema) name\n",
    "    host = \"127.0.0.1\"  # update with your own cloud SQL instance public IP address\n",
    "    user = \"root\"  # update with your MySql username\n",
    "    password = \"password\" # update \"password\" with your actual MySql password\n",
    "    port = 3306  # update with your own default MySQL port, if different\n",
    "    connection_string = f\"mysql+pymysql://{user}:{password}@{host}:{port}/{schema}\"\n",
    "    return connection_string\n",
    "    \n",
    "def insert_population_data_in_SQL(connection_string):\n",
    "    cities_population = []\n",
    "    cities_from_sql = pd.read_sql(\"cities\", con=connection_string)\n",
    "    cities = cities_from_sql[\"city\"].to_list()\n",
    "\n",
    "    for city in cities:\n",
    "      city_population = {}\n",
    "\n",
    "      #connecting to website\n",
    "      city_population [\"city\"] = city #adding city name to dictionnary\n",
    "      city = city.replace(' ', '_') #replacing space for \"_\" in city names composed of two names, i.e. New York\n",
    "      url = f'https://en.wikipedia.org/wiki/{city}' #target website for scraping\n",
    "      response = requests.get(url)\n",
    "\n",
    "      #creating soup\n",
    "      if response.status_code == 200: #checking status code; if ok, proceed.\n",
    "        soup = BeautifulSoup(response.content, 'html.parser') #creating soup.\n",
    "\n",
    "        #scraping city population\n",
    "        pop = soup.find(class_=\"infobox ib-settlement vcard\").find(string=\"Population\").find_next(\"td\").get_text() #getting population information.\n",
    "        pop = int(pop.replace(\",\", \"\")) #removing commas from figure and making it an integer\n",
    "        city_population [\"population\"] = pop #sending info to dictionary\n",
    "\n",
    "        #scraping population timestamp (year)\n",
    "        def extract_year (date):\n",
    "            pattern = r'\\b\\d{4}\\b' # Regular expression pattern to match a four-digit year\n",
    "            matches = re.findall(pattern, date)# Find all matches of the pattern in the input string\n",
    "            if matches:# Extract the first match if available\n",
    "                year = matches[0]\n",
    "            else:\n",
    "                print(\"No year found\")\n",
    "            return year\n",
    "            \n",
    "        yr = extract_year(soup.find(class_=\"infobox ib-settlement vcard\").find(string=\"Population\").next_sibling.get_text())#getting year for population information.\n",
    "\n",
    "\n",
    "        city_population [\"year\"]= yr #sending info to dictionary\n",
    "      \n",
    "        cities_population.append(city_population)\n",
    "\n",
    "    merged_population = cities_from_sql.merge((pd.DataFrame(cities_population)),\n",
    "                                   on = \"city\",\n",
    "                                   how=\"left\")\n",
    "\n",
    "    population_df = merged_population[['city_id','population','year']]\n",
    "\n",
    "    population_from_sql = pd.read_sql('population', con=connection_string)\n",
    "\n",
    "    def append_if_not_duplicate (df1, df2): #df1 = updates, df2 = existing_table\n",
    "        unique_rows = df1[~df1.apply(tuple, axis=1).isin(df2.apply(tuple, axis=1))]\n",
    "        \n",
    "        updated_df2 = pd.concat([df2, unique_rows], ignore_index=True)\n",
    "        \n",
    "\n",
    "    updated_population_table = append_if_not_duplicate(population_df, population_from_sql)\n",
    "    \n",
    "    if updated_population_table:\n",
    "        updated_population_table.to_sql('population',\n",
    "                                        if_exists='append',\n",
    "                                        con=connection_string,\n",
    "                                        index=False)\n",
    "    else:\n",
    "        print(\"There is no new population information\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
